{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['input', 'notebook', 'output']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "print(os.listdir('/cos_person/'))\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py:3020: DtypeWarning: Columns (5,8,11,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py:3020: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('/cos_person/input/train_ver2.csv')\n",
    "test = pd.read_csv('/cos_person/input/test_ver2.csv')\n",
    "submission = pd.read_csv('/cos_person/input/sample_submission.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 2342.72 Mb (53.1% reduction)\n",
      "Mem. usage decreased to 122.34 Mb (28.1% reduction)\n",
      "Mem. usage decreased to 10.64 Mb (25.0% reduction)\n"
     ]
    }
   ],
   "source": [
    "train=reduce_mem_usage(train)\n",
    "test=reduce_mem_usage(test)\n",
    "submission=reduce_mem_usage(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix=pd.concat([train, test], ignore_index=True, sort=False)\n",
    "#填充缺失值，用什么填充还需待定\n",
    "matrix.fillna(-999, inplace=True)\n",
    "#drop掉没用的特征\n",
    "matrix.drop(['fecha_alta','ult_fec_cli_1t','tipodom','cod_prov'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fecha_dato</th>\n",
       "      <th>ncodpers</th>\n",
       "      <th>ind_empleado</th>\n",
       "      <th>pais_residencia</th>\n",
       "      <th>sexo</th>\n",
       "      <th>age</th>\n",
       "      <th>ind_nuevo</th>\n",
       "      <th>antiguedad</th>\n",
       "      <th>indrel</th>\n",
       "      <th>indrel_1mes</th>\n",
       "      <th>tiprel_1mes</th>\n",
       "      <th>indresi</th>\n",
       "      <th>indext</th>\n",
       "      <th>conyuemp</th>\n",
       "      <th>canal_entrada</th>\n",
       "      <th>indfall</th>\n",
       "      <th>nomprov</th>\n",
       "      <th>ind_actividad_cliente</th>\n",
       "      <th>renta</th>\n",
       "      <th>segmento</th>\n",
       "      <th>ind_ahor_fin_ult1</th>\n",
       "      <th>ind_aval_fin_ult1</th>\n",
       "      <th>ind_cco_fin_ult1</th>\n",
       "      <th>ind_cder_fin_ult1</th>\n",
       "      <th>ind_cno_fin_ult1</th>\n",
       "      <th>ind_ctju_fin_ult1</th>\n",
       "      <th>ind_ctma_fin_ult1</th>\n",
       "      <th>ind_ctop_fin_ult1</th>\n",
       "      <th>ind_ctpp_fin_ult1</th>\n",
       "      <th>ind_deco_fin_ult1</th>\n",
       "      <th>ind_deme_fin_ult1</th>\n",
       "      <th>ind_dela_fin_ult1</th>\n",
       "      <th>ind_ecue_fin_ult1</th>\n",
       "      <th>ind_fond_fin_ult1</th>\n",
       "      <th>ind_hip_fin_ult1</th>\n",
       "      <th>ind_plan_fin_ult1</th>\n",
       "      <th>ind_pres_fin_ult1</th>\n",
       "      <th>ind_reca_fin_ult1</th>\n",
       "      <th>ind_tjcr_fin_ult1</th>\n",
       "      <th>ind_valo_fin_ult1</th>\n",
       "      <th>ind_viv_fin_ult1</th>\n",
       "      <th>ind_nomina_ult1</th>\n",
       "      <th>ind_nom_pens_ult1</th>\n",
       "      <th>ind_recibo_ult1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-28</td>\n",
       "      <td>1375586</td>\n",
       "      <td>N</td>\n",
       "      <td>ES</td>\n",
       "      <td>H</td>\n",
       "      <td>35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>S</td>\n",
       "      <td>N</td>\n",
       "      <td>-999</td>\n",
       "      <td>KHL</td>\n",
       "      <td>N</td>\n",
       "      <td>MALAGA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>87218.1</td>\n",
       "      <td>02 - PARTICULARES</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-28</td>\n",
       "      <td>1050611</td>\n",
       "      <td>N</td>\n",
       "      <td>ES</td>\n",
       "      <td>V</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>I</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>-999</td>\n",
       "      <td>KHE</td>\n",
       "      <td>N</td>\n",
       "      <td>CIUDAD REAL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35548.7</td>\n",
       "      <td>03 - UNIVERSITARIO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-28</td>\n",
       "      <td>1050612</td>\n",
       "      <td>N</td>\n",
       "      <td>ES</td>\n",
       "      <td>V</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>I</td>\n",
       "      <td>S</td>\n",
       "      <td>N</td>\n",
       "      <td>-999</td>\n",
       "      <td>KHE</td>\n",
       "      <td>N</td>\n",
       "      <td>CIUDAD REAL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>122179</td>\n",
       "      <td>03 - UNIVERSITARIO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-28</td>\n",
       "      <td>1050613</td>\n",
       "      <td>N</td>\n",
       "      <td>ES</td>\n",
       "      <td>H</td>\n",
       "      <td>22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>I</td>\n",
       "      <td>S</td>\n",
       "      <td>N</td>\n",
       "      <td>-999</td>\n",
       "      <td>KHD</td>\n",
       "      <td>N</td>\n",
       "      <td>ZARAGOZA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>119776</td>\n",
       "      <td>03 - UNIVERSITARIO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-28</td>\n",
       "      <td>1050614</td>\n",
       "      <td>N</td>\n",
       "      <td>ES</td>\n",
       "      <td>V</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>S</td>\n",
       "      <td>N</td>\n",
       "      <td>-999</td>\n",
       "      <td>KHE</td>\n",
       "      <td>N</td>\n",
       "      <td>ZARAGOZA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-999</td>\n",
       "      <td>03 - UNIVERSITARIO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fecha_dato  ncodpers ind_empleado pais_residencia sexo  age  ind_nuevo  \\\n",
       "0  2015-01-28   1375586            N              ES    H   35        0.0   \n",
       "1  2015-01-28   1050611            N              ES    V   23        0.0   \n",
       "2  2015-01-28   1050612            N              ES    V   23        0.0   \n",
       "3  2015-01-28   1050613            N              ES    H   22        0.0   \n",
       "4  2015-01-28   1050614            N              ES    V   23        0.0   \n",
       "\n",
       "  antiguedad  indrel indrel_1mes tiprel_1mes indresi indext conyuemp  \\\n",
       "0          6     1.0           1           A       S      N     -999   \n",
       "1         35     1.0           1           I       S      S     -999   \n",
       "2         35     1.0           1           I       S      N     -999   \n",
       "3         35     1.0           1           I       S      N     -999   \n",
       "4         35     1.0           1           A       S      N     -999   \n",
       "\n",
       "  canal_entrada indfall      nomprov  ind_actividad_cliente    renta  \\\n",
       "0           KHL       N       MALAGA                    1.0  87218.1   \n",
       "1           KHE       N  CIUDAD REAL                    0.0  35548.7   \n",
       "2           KHE       N  CIUDAD REAL                    0.0   122179   \n",
       "3           KHD       N     ZARAGOZA                    0.0   119776   \n",
       "4           KHE       N     ZARAGOZA                    1.0     -999   \n",
       "\n",
       "             segmento  ind_ahor_fin_ult1  ind_aval_fin_ult1  ind_cco_fin_ult1  \\\n",
       "0   02 - PARTICULARES                0.0                0.0               1.0   \n",
       "1  03 - UNIVERSITARIO                0.0                0.0               1.0   \n",
       "2  03 - UNIVERSITARIO                0.0                0.0               1.0   \n",
       "3  03 - UNIVERSITARIO                0.0                0.0               0.0   \n",
       "4  03 - UNIVERSITARIO                0.0                0.0               1.0   \n",
       "\n",
       "   ind_cder_fin_ult1  ind_cno_fin_ult1  ind_ctju_fin_ult1  ind_ctma_fin_ult1  \\\n",
       "0                0.0               0.0                0.0                0.0   \n",
       "1                0.0               0.0                0.0                0.0   \n",
       "2                0.0               0.0                0.0                0.0   \n",
       "3                0.0               0.0                0.0                0.0   \n",
       "4                0.0               0.0                0.0                0.0   \n",
       "\n",
       "   ind_ctop_fin_ult1  ind_ctpp_fin_ult1  ind_deco_fin_ult1  ind_deme_fin_ult1  \\\n",
       "0                0.0                0.0                0.0                0.0   \n",
       "1                0.0                0.0                0.0                0.0   \n",
       "2                0.0                0.0                0.0                0.0   \n",
       "3                0.0                0.0                1.0                0.0   \n",
       "4                0.0                0.0                0.0                0.0   \n",
       "\n",
       "   ind_dela_fin_ult1  ind_ecue_fin_ult1  ind_fond_fin_ult1  ind_hip_fin_ult1  \\\n",
       "0                0.0                0.0                0.0               0.0   \n",
       "1                0.0                0.0                0.0               0.0   \n",
       "2                0.0                0.0                0.0               0.0   \n",
       "3                0.0                0.0                0.0               0.0   \n",
       "4                0.0                0.0                0.0               0.0   \n",
       "\n",
       "   ind_plan_fin_ult1  ind_pres_fin_ult1  ind_reca_fin_ult1  ind_tjcr_fin_ult1  \\\n",
       "0                0.0                0.0                0.0                0.0   \n",
       "1                0.0                0.0                0.0                0.0   \n",
       "2                0.0                0.0                0.0                0.0   \n",
       "3                0.0                0.0                0.0                0.0   \n",
       "4                0.0                0.0                0.0                0.0   \n",
       "\n",
       "   ind_valo_fin_ult1  ind_viv_fin_ult1  ind_nomina_ult1  ind_nom_pens_ult1  \\\n",
       "0                0.0               0.0              0.0                0.0   \n",
       "1                0.0               0.0              0.0                0.0   \n",
       "2                0.0               0.0              0.0                0.0   \n",
       "3                0.0               0.0              0.0                0.0   \n",
       "4                0.0               0.0              0.0                0.0   \n",
       "\n",
       "   ind_recibo_ult1  \n",
       "0              0.0  \n",
       "1              0.0  \n",
       "2              0.0  \n",
       "3              0.0  \n",
       "4              0.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fecha_dato', 'ncodpers', 'ind_empleado', 'pais_residencia', 'sexo',\n",
       "       'age', 'ind_nuevo', 'antiguedad', 'indrel', 'indrel_1mes',\n",
       "       'tiprel_1mes', 'indresi', 'indext', 'conyuemp', 'canal_entrada',\n",
       "       'indfall', 'nomprov', 'ind_actividad_cliente', 'renta', 'segmento',\n",
       "       'ind_ahor_fin_ult1', 'ind_aval_fin_ult1', 'ind_cco_fin_ult1',\n",
       "       'ind_cder_fin_ult1', 'ind_cno_fin_ult1', 'ind_ctju_fin_ult1',\n",
       "       'ind_ctma_fin_ult1', 'ind_ctop_fin_ult1', 'ind_ctpp_fin_ult1',\n",
       "       'ind_deco_fin_ult1', 'ind_deme_fin_ult1', 'ind_dela_fin_ult1',\n",
       "       'ind_ecue_fin_ult1', 'ind_fond_fin_ult1', 'ind_hip_fin_ult1',\n",
       "       'ind_plan_fin_ult1', 'ind_pres_fin_ult1', 'ind_reca_fin_ult1',\n",
       "       'ind_tjcr_fin_ult1', 'ind_valo_fin_ult1', 'ind_viv_fin_ult1',\n",
       "       'ind_nomina_ult1', 'ind_nom_pens_ult1', 'ind_recibo_ult1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#将数据集按月份切割出来，d1512代表15年12月，d167代表16年7月，以此类推\n",
    "\n",
    "matrix['fecha_dato']=pd.to_datetime(matrix['fecha_dato'],)\n",
    "varia_list=locals()\n",
    "for i in range(1,13):\n",
    "       varia_list['d15'+str(i)]=matrix[(matrix.fecha_dato.dt.year==2015) & (matrix.fecha_dato.dt.month==i)]\n",
    "for i in range(1,7):\n",
    "       varia_list['d16'+str(i)]=matrix[(matrix.fecha_dato.dt.year==2016) & (matrix.fecha_dato.dt.month==i)]\n",
    "del matrix\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将上个月对应的值做为这个月的特征，对所有数据集进行处理\n",
    "def get_last_month_feat(features=[]):\n",
    "    if len(features)==0:\n",
    "      return\n",
    "#2015年\n",
    "    for feat in features:\n",
    "      for i in range(2,13):\n",
    "         temp=varia_list['d15'+str(i-1)].loc[:,['ncodpers',feat]].rename(columns={feat:feat+'_last_month'}) \n",
    "         varia_list['d15'+str(i)] =  varia_list['d15'+str(i)].merge(temp, on='ncodpers', how='left')\n",
    "#2016年\n",
    "      for i in range(2,7):\n",
    "         temp=varia_list['d16'+str(i-1)].loc[:,['ncodpers',feat]].rename(columns={feat:feat+'_last_month'}) \n",
    "         varia_list['d16'+str(i)] =  varia_list['d16'+str(i)].merge(temp, on='ncodpers', how='left')\n",
    "#2015-2016年的转折\n",
    "      temp=varia_list['d15'+str(12)].loc[:,['ncodpers',feat]].rename(columns={feat:feat+'_last_month'}) \n",
    "      varia_list['d16'+str(1)] =  varia_list['d16'+str(1)].merge(temp, on='ncodpers', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "products=[ 'ind_cco_fin_ult1','ind_cder_fin_ult1', 'ind_cno_fin_ult1', 'ind_ctju_fin_ult1',\n",
    "       'ind_ctma_fin_ult1', 'ind_ctop_fin_ult1', 'ind_ctpp_fin_ult1',\n",
    "       'ind_dela_fin_ult1', 'ind_ecue_fin_ult1', 'ind_fond_fin_ult1', 'ind_hip_fin_ult1',\n",
    "       'ind_plan_fin_ult1', 'ind_pres_fin_ult1', 'ind_reca_fin_ult1',\n",
    "       'ind_tjcr_fin_ult1', 'ind_valo_fin_ult1', 'ind_viv_fin_ult1',\n",
    "       'ind_nomina_ult1', 'ind_nom_pens_ult1', 'ind_recibo_ult1']\n",
    "\n",
    "features=products+['ind_actividad_cliente','tiprel_1mes']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 累计到上个月0-0，0-1，1-0，1-1模式转变的个数，对所有数据集进行处理，特别冗长，早知不把数据集的名字按年份分开命名\n",
    "def count_index_change_pattern(features=[]):\n",
    "   if len(features)==0:\n",
    "     return\n",
    "   for feat in features:\n",
    "#2015年    \n",
    "        for i in range(2,12):        \n",
    "            varia_list['d15'+str(i)][feat+'_00_save']=np.zeros((varia_list['d15'+str(i)].shape[0],))\n",
    "            varia_list['d15'+str(i)][feat+'_01_save']=np.zeros((varia_list['d15'+str(i)].shape[0],))\n",
    "            varia_list['d15'+str(i)][feat+'_10_save']=np.zeros((varia_list['d15'+str(i)].shape[0],))\n",
    "            varia_list['d15'+str(i)][feat+'_11_save']=np.zeros((varia_list['d15'+str(i)].shape[0],))\n",
    "# COUNT 0 TO 0\n",
    "            if feat+'_00' in varia_list['d15'+str(i)].columns:\n",
    "               varia_list['d15'+str(i)].loc[(varia_list['d15'+str(i)][feat+'_last_month']==0) & (varia_list['d15'+str(i)][feat]==0),[feat+'_00_save']]= varia_list['d15'+str(i)].loc[(varia_list['d15'+str(i)][feat+'_last_month']==0) & (varia_list['d15'+str(i)][feat]==0),][feat+'_00'].apply(lambda x:1 if pd.isnull(x) else int(x)+1)\n",
    "            else:\n",
    "               varia_list['d15'+str(i)].loc[(varia_list['d15'+str(i)][feat+'_last_month']==0) & (varia_list['d15'+str(i)][feat]==0),[feat+'_00_save']]=1\n",
    "            temp=varia_list['d15'+str(i)].loc[:,['ncodpers',feat+'_00_save']].rename(columns={feat+'_00_save':feat+'_00'}) \n",
    "            varia_list['d15'+str(i+1)] =  varia_list['d15'+str(i+1)].merge(temp, on='ncodpers', how='left')\n",
    "# COUNT 0 TO 1\n",
    "            if feat+'_01' in varia_list['d15'+str(i)].columns:\n",
    "               varia_list['d15'+str(i)].loc[(varia_list['d15'+str(i)][feat+'_last_month']==0) & (varia_list['d15'+str(i)][feat]==1),[feat+'_01_save']]= varia_list['d15'+str(i)].loc[(varia_list['d15'+str(i)][feat+'_last_month']==0) & (varia_list['d15'+str(i)][feat]==1),][feat+'_01'].apply(lambda x:1 if pd.isnull(x) else int(x)+1)\n",
    "            else:\n",
    "               varia_list['d15'+str(i)].loc[(varia_list['d15'+str(i)][feat+'_last_month']==0) & (varia_list['d15'+str(i)][feat]==1),[feat+'_01_save']]=1\n",
    "            temp=varia_list['d15'+str(i)].loc[:,['ncodpers',feat+'_01_save']].rename(columns={feat+'_01_save':feat+'_01'}) \n",
    "            varia_list['d15'+str(i+1)] =  varia_list['d15'+str(i+1)].merge(temp, on='ncodpers', how='left')       \n",
    "# COUNT 1 TO 0\n",
    "            if feat+'_10' in varia_list['d15'+str(i)].columns:\n",
    "               varia_list['d15'+str(i)].loc[(varia_list['d15'+str(i)][feat+'_last_month']==1) & (varia_list['d15'+str(i)][feat]==0),[feat+'_10_save']]= varia_list['d15'+str(i)].loc[(varia_list['d15'+str(i)][feat+'_last_month']==1) & (varia_list['d15'+str(i)][feat]==0),][feat+'_10'].apply(lambda x:1 if pd.isnull(x) else int(x)+1)\n",
    "            else:\n",
    "               varia_list['d15'+str(i)].loc[(varia_list['d15'+str(i)][feat+'_last_month']==1) & (varia_list['d15'+str(i)][feat]==0),[feat+'_10_save']]=1\n",
    "            temp=varia_list['d15'+str(i)].loc[:,['ncodpers',feat+'_10_save']].rename(columns={feat+'_10_save':feat+'_10'}) \n",
    "            varia_list['d15'+str(i+1)] =  varia_list['d15'+str(i+1)].merge(temp, on='ncodpers', how='left') \n",
    "# COUNT 1 TO 1\n",
    "            if feat+'_11' in varia_list['d15'+str(i)].columns:\n",
    "               varia_list['d15'+str(i)].loc[(varia_list['d15'+str(i)][feat+'_last_month']==1) & (varia_list['d15'+str(i)][feat]==1),[feat+'_11_save']]= varia_list['d15'+str(i)].loc[(varia_list['d15'+str(i)][feat+'_last_month']==1) & (varia_list['d15'+str(i)][feat]==1),][feat+'_11'].apply(lambda x:1 if pd.isnull(x) else int(x)+1)\n",
    "            else:\n",
    "               varia_list['d15'+str(i)].loc[(varia_list['d15'+str(i)][feat+'_last_month']==1) & (varia_list['d15'+str(i)][feat]==1),[feat+'_11_save']]=1\n",
    "            temp=varia_list['d15'+str(i)].loc[:,['ncodpers',feat+'_11_save']].rename(columns={feat+'_11_save':feat+'_11'}) \n",
    "            varia_list['d15'+str(i+1)] =  varia_list['d15'+str(i+1)].merge(temp, on='ncodpers', how='left') \n",
    "\n",
    "#2015-2016年的转折            \n",
    "        varia_list['d15'+str(12)][feat+'_00_save']=np.zeros((varia_list['d15'+str(12)].shape[0],))\n",
    "        varia_list['d15'+str(12)][feat+'_01_save']=np.zeros((varia_list['d15'+str(12)].shape[0],))\n",
    "        varia_list['d15'+str(12)][feat+'_10_save']=np.zeros((varia_list['d15'+str(12)].shape[0],))\n",
    "        varia_list['d15'+str(12)][feat+'_11_save']=np.zeros((varia_list['d15'+str(12)].shape[0],))\n",
    "# COUNT 0 TO 0\n",
    "        if feat+'_00' in varia_list['d15'+str(12)].columns:\n",
    "           varia_list['d15'+str(12)].loc[(varia_list['d15'+str(12)][feat+'_last_month']==0) & (varia_list['d15'+str(12)][feat]==0),[feat+'_00_save']]= varia_list['d15'+str(12)].loc[(varia_list['d15'+str(12)][feat+'_last_month']==0) & (varia_list['d15'+str(12)][feat]==0),][feat+'_00'].apply(lambda x:1 if pd.isnull(x) else int(x)+1)\n",
    "        else:\n",
    "           varia_list['d15'+str(12)].loc[(varia_list['d15'+str(12)][feat+'_last_month']==0) & (varia_list['d15'+str(12)][feat]==0),[feat+'_00_save']]=1\n",
    "        temp=varia_list['d15'+str(12)].loc[:,['ncodpers',feat+'_00_save']].rename(columns={feat+'_00_save':feat+'_00'}) \n",
    "        varia_list['d16'+str(1)] =  varia_list['d16'+str(1)].merge(temp, on='ncodpers', how='left')\n",
    "# COUNT 0 TO 1\n",
    "        if feat+'_01' in varia_list['d15'+str(12)].columns:\n",
    "           varia_list['d15'+str(12)].loc[(varia_list['d15'+str(12)][feat+'_last_month']==0) & (varia_list['d15'+str(12)][feat]==1),[feat+'_01_save']]= varia_list['d15'+str(i)].loc[(varia_list['d15'+str(i)][feat+'_last_month']==0) & (varia_list['d15'+str(i)][feat]==1),][feat+'_01'].apply(lambda x:1 if pd.isnull(x) else int(x)+1)\n",
    "        else:\n",
    "           varia_list['d15'+str(12)].loc[(varia_list['d15'+str(12)][feat+'_last_month']==0) & (varia_list['d15'+str(12)][feat]==1),[feat+'_01_save']]=1\n",
    "        temp=varia_list['d15'+str(12)].loc[:,['ncodpers',feat+'_01_save']].rename(columns={feat+'_01_save':feat+'_01'}) \n",
    "        varia_list['d16'+str(1)] =  varia_list['d16'+str(1)].merge(temp, on='ncodpers', how='left')       \n",
    "# COUNT 1 TO 0\n",
    "        if feat+'_10' in varia_list['d15'+str(12)].columns:\n",
    "           varia_list['d15'+str(12)].loc[(varia_list['d15'+str(12)][feat+'_last_month']==1) & (varia_list['d15'+str(12)][feat]==0),[feat+'_10_save']]= varia_list['d15'+str(i)].loc[(varia_list['d15'+str(i)][feat+'_last_month']==1) & (varia_list['d15'+str(i)][feat]==0),][feat+'_10'].apply(lambda x:1 if pd.isnull(x) else int(x)+1)\n",
    "        else:\n",
    "           varia_list['d15'+str(12)].loc[(varia_list['d15'+str(12)][feat+'_last_month']==1) & (varia_list['d15'+str(12)][feat]==0),[feat+'_10_save']]=1\n",
    "        temp=varia_list['d15'+str(12)].loc[:,['ncodpers',feat+'_10_save']].rename(columns={feat+'_10_save':feat+'_10'}) \n",
    "        varia_list['d16'+str(1)] =  varia_list['d16'+str(1)].merge(temp, on='ncodpers', how='left') \n",
    "# COUNT 1 TO 1\n",
    "        if feat+'_11' in varia_list['d15'+str(12)].columns:\n",
    "           varia_list['d15'+str(12)].loc[(varia_list['d15'+str(12)][feat+'_last_month']==1) & (varia_list['d15'+str(12)][feat]==1),[feat+'_11_save']]= varia_list['d15'+str(i)].loc[(varia_list['d15'+str(i)][feat+'_last_month']==1) & (varia_list['d15'+str(i)][feat]==1),][feat+'_11'].apply(lambda x:1 if pd.isnull(x) else int(x)+1)\n",
    "        else:\n",
    "           varia_list['d15'+str(12)].loc[(varia_list['d15'+str(12)][feat+'_last_month']==1) & (varia_list['d15'+str(12)][feat]==1),[feat+'_11_save']]=1\n",
    "        temp=varia_list['d15'+str(12)].loc[:,['ncodpers',feat+'_11_save']].rename(columns={feat+'_11_save':feat+'_11'}) \n",
    "        varia_list['d16'+str(1)] =  varia_list['d16'+str(1)].merge(temp, on='ncodpers', how='left') \n",
    "\n",
    "# 2016年\n",
    "        for i in range(1,6):        \n",
    "            varia_list['d16'+str(i)][feat+'_00_save']=np.zeros((varia_list['d16'+str(i)].shape[0],))\n",
    "            varia_list['d16'+str(i)][feat+'_01_save']=np.zeros((varia_list['d16'+str(i)].shape[0],))\n",
    "            varia_list['d16'+str(i)][feat+'_10_save']=np.zeros((varia_list['d16'+str(i)].shape[0],))\n",
    "            varia_list['d16'+str(i)][feat+'_11_save']=np.zeros((varia_list['d16'+str(i)].shape[0],))\n",
    "# COUNT 0 TO 0\n",
    "            if feat+'_00' in varia_list['d16'+str(i)].columns:\n",
    "               varia_list['d16'+str(i)].loc[(varia_list['d16'+str(i)][feat+'_last_month']==0) & (varia_list['d16'+str(i)][feat]==0),[feat+'_00_save']]= varia_list['d16'+str(i)].loc[(varia_list['d16'+str(i)][feat+'_last_month']==0) & (varia_list['d16'+str(i)][feat]==0),][feat+'_00'].apply(lambda x:1 if pd.isnull(x) else int(x)+1)\n",
    "            else:\n",
    "               varia_list['d16'+str(i)].loc[(varia_list['d16'+str(i)][feat+'_last_month']==0) & (varia_list['d16'+str(i)][feat]==0),[feat+'_00_save']]=1   \n",
    "            temp=varia_list['d16'+str(i)].loc[:,['ncodpers',feat+'_00_save']].rename(columns={feat+'_00_save':feat+'_00'}) \n",
    "            varia_list['d16'+str(i+1)] =  varia_list['d16'+str(i+1)].merge(temp, on='ncodpers', how='left')\n",
    "\n",
    "# COUNT 0 TO 1\n",
    "            if feat+'_01' in varia_list['d16'+str(i)].columns:\n",
    "               varia_list['d16'+str(i)].loc[(varia_list['d16'+str(i)][feat+'_last_month']==0) & (varia_list['d16'+str(i)][feat]==1),[feat+'_01_save']]= varia_list['d16'+str(i)].loc[(varia_list['d16'+str(i)][feat+'_last_month']==0) & (varia_list['d16'+str(i)][feat]==1),][feat+'_01'].apply(lambda x:1 if pd.isnull(x) else int(x)+1)\n",
    "            else:\n",
    "               varia_list['d16'+str(i)].loc[(varia_list['d16'+str(i)][feat+'_last_month']==0) & (varia_list['d16'+str(i)][feat]==1),[feat+'_01_save']]=1\n",
    "            temp=varia_list['d16'+str(i)].loc[:,['ncodpers',feat+'_01_save']].rename(columns={feat+'_01_save':feat+'_01'}) \n",
    "            varia_list['d16'+str(i+1)] =  varia_list['d16'+str(i+1)].merge(temp, on='ncodpers', how='left')       \n",
    "# COUNT 1 TO 0\n",
    "            if feat+'_10' in varia_list['d16'+str(i)].columns:\n",
    "               varia_list['d16'+str(i)].loc[(varia_list['d16'+str(i)][feat+'_last_month']==1) & (varia_list['d16'+str(i)][feat]==0),[feat+'_10_save']]= varia_list['d16'+str(i)].loc[(varia_list['d16'+str(i)][feat+'_last_month']==1) & (varia_list['d16'+str(i)][feat]==0),][feat+'_10'].apply(lambda x:1 if pd.isnull(x) else int(x)+1)\n",
    "            else:\n",
    "               varia_list['d16'+str(i)].loc[(varia_list['d16'+str(i)][feat+'_last_month']==1) & (varia_list['d16'+str(i)][feat]==0),[feat+'_10_save']]=1\n",
    "            temp=varia_list['d16'+str(i)].loc[:,['ncodpers',feat+'_10_save']].rename(columns={feat+'_10_save':feat+'_10'}) \n",
    "            varia_list['d16'+str(i+1)] =  varia_list['d16'+str(i+1)].merge(temp, on='ncodpers', how='left') \n",
    "# COUNT 1 TO 1\n",
    "            if feat+'_11' in varia_list['d16'+str(i)].columns:\n",
    "               varia_list['d16'+str(i)].loc[(varia_list['d16'+str(i)][feat+'_last_month']==1) & (varia_list['d16'+str(i)][feat]==1),[feat+'_11_save']]= varia_list['d16'+str(i)].loc[(varia_list['d16'+str(i)][feat+'_last_month']==1) & (varia_list['d16'+str(i)][feat]==1),][feat+'_11'].apply(lambda x:1 if pd.isnull(x) else int(x)+1)\n",
    "            else:\n",
    "               varia_list['d16'+str(i)].loc[(varia_list['d16'+str(i)][feat+'_last_month']==1) & (varia_list['d16'+str(i)][feat]==1),[feat+'_11_save']]=1\n",
    "            temp=varia_list['d16'+str(i)].loc[:,['ncodpers',feat+'_11_save']].rename(columns={feat+'_11_save':feat+'_11'}) \n",
    "            varia_list['d16'+str(i+1)] =  varia_list['d16'+str(i+1)].merge(temp, on='ncodpers', how='left') \n",
    "        for i in  range(2,13):\n",
    "            varia_list['d15'+str(i)].drop([feat+'_00_save',feat+'_01_save',feat+'_10_save',feat+'_11_save'],axis=1, inplace=True)\n",
    "        for i in range(1,6):\n",
    "            varia_list['d16'+str(i)].drop([feat+'_00_save',feat+'_01_save',feat+'_10_save',feat+'_11_save'],axis=1, inplace=True)\n",
    "\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#上个月买了几个产品,对所有数据集统一处理\n",
    "products=[ 'ind_cco_fin_ult1',\n",
    "       'ind_cder_fin_ult1', 'ind_cno_fin_ult1', 'ind_ctju_fin_ult1',\n",
    "       'ind_ctma_fin_ult1', 'ind_ctop_fin_ult1', 'ind_ctpp_fin_ult1','ind_dela_fin_ult1', 'ind_ecue_fin_ult1', 'ind_fond_fin_ult1', 'ind_hip_fin_ult1',\n",
    "       'ind_plan_fin_ult1', 'ind_pres_fin_ult1', 'ind_reca_fin_ult1',\n",
    "       'ind_tjcr_fin_ult1', 'ind_valo_fin_ult1', 'ind_viv_fin_ult1',\n",
    "       'ind_nomina_ult1', 'ind_nom_pens_ult1', 'ind_recibo_ult1']\n",
    "\n",
    "def get_n_products_last():\n",
    "#2015年    \n",
    "   for i in range(2,12): \n",
    "       varia_list['d15'+str(i)]['n_products_this']=np.zeros((varia_list['d15'+str(i)].shape[0],))\n",
    "       for feat in products:\n",
    "            varia_list['d15'+str(i)].loc[(varia_list['d15'+str(i)][feat+'_last_month']==0) & (varia_list['d15'+str(i)][feat]==1),['n_products_this']]=varia_list['d15'+str(i)].loc[(varia_list['d15'+str(i)][feat+'_last_month']==0) & (varia_list['d15'+str(i)][feat]==1),]['n_products_this'].apply(lambda x:int(x)+1) \n",
    "       temp=varia_list['d15'+str(i)].loc[:,['ncodpers','n_products_this']].rename(columns={'n_products_this':'n_products_last'}) \n",
    "       varia_list['d15'+str(i+1)] =  varia_list['d15'+str(i+1)].merge(temp, on='ncodpers', how='left') \n",
    "#2015-2016年的转折 \n",
    "   varia_list['d15'+str(12)]['n_products_this']=np.zeros((varia_list['d15'+str(12)].shape[0],))\n",
    "   for feat in products:\n",
    "        varia_list['d15'+str(12)].loc[(varia_list['d15'+str(12)][feat+'_last_month']==0) & (varia_list['d15'+str(12)][feat]==1),['n_products_this']]=varia_list['d15'+str(12)].loc[(varia_list['d15'+str(12)][feat+'_last_month']==0) & (varia_list['d15'+str(12)][feat]==1),]['n_products_this'].apply(lambda x:int(x)+1) \n",
    "   temp=varia_list['d15'+str(12)].loc[:,['ncodpers','n_products_this']].rename(columns={'n_products_this':'n_products_last'}) \n",
    "   varia_list['d16'+str(1)] =  varia_list['d16'+str(1)].merge(temp, on='ncodpers', how='left') \n",
    "#2016年\n",
    "   for i in range(1,6): \n",
    "       varia_list['d16'+str(i)]['n_products_this']=np.zeros((varia_list['d16'+str(i)].shape[0],))\n",
    "       for feat in products:\n",
    "            varia_list['d16'+str(i)].loc[(varia_list['d16'+str(i)][feat+'_last_month']==0) & (varia_list['d16'+str(i)][feat]==1),['n_products_this']]=varia_list['d16'+str(i)].loc[(varia_list['d16'+str(i)][feat+'_last_month']==0) & (varia_list['d16'+str(i)][feat]==1),]['n_products_this'].apply(lambda x:int(x)+1) \n",
    "       temp=varia_list['d16'+str(i)].loc[:,['ncodpers','n_products_this']].rename(columns={'n_products_this':'n_products_last'}) \n",
    "       varia_list['d16'+str(i+1)] =  varia_list['d16'+str(i+1)].merge(temp, on='ncodpers', how='left')\n",
    "#drop掉那些只用来存储中间值的特征\n",
    "   for i in range(2,13):\n",
    "       varia_list['d15'+str(i)].drop(['n_products_this'],axis=1, inplace=True)\n",
    "   for i in range(1,6):\n",
    "       varia_list['d16'+str(i)].drop(['n_products_this'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#length of continuous 0 index until last month，截止到上个月为止共有几个0，对所有数据集统一处理\n",
    "def get_length_conti0(features=[]):\n",
    "    if len(features)==0:\n",
    "      return\n",
    "    for feat in features:\n",
    "#2015年        \n",
    "        for i in range(1,12): \n",
    "            varia_list['d15'+str(i)][feat+'_0len_save']=np.zeros((varia_list['d15'+str(i)].shape[0],))\n",
    "            if feat+'_0len' in  varia_list['d15'+str(i)].columns:\n",
    "               varia_list['d15'+str(i)].loc[(varia_list['d15'+str(i)][feat]==0),[feat+'_0len_save']]=varia_list['d15'+str(i)].loc[(varia_list['d15'+str(i)][feat]==0),][feat+'_0len'].apply(lambda x:1 if pd.isnull(x) else int(x)+1)\n",
    "               varia_list['d15'+str(i)].loc[(varia_list['d15'+str(i)][feat]==1),[feat+'_0len_save']]=0\n",
    "            else:\n",
    "               varia_list['d15'+str(i)].loc[(varia_list['d15'+str(i)][feat]==0),[feat+'_0len_save']]=1\n",
    "            temp=varia_list['d15'+str(i)].loc[:,['ncodpers',feat+'_0len_save']].rename(columns={feat+'_0len_save':feat+'_0len'}) \n",
    "            varia_list['d15'+str(i+1)] =  varia_list['d15'+str(i+1)].merge(temp, on='ncodpers', how='left')  \n",
    "#2015-2016年的转折 \n",
    "        varia_list['d15'+str(12)][feat+'_0len_save']=np.zeros((varia_list['d15'+str(12)].shape[0],))\n",
    "        if feat+'_0len' in  varia_list['d15'+str(12)].columns:\n",
    "            varia_list['d15'+str(12)].loc[(varia_list['d15'+str(12)][feat]==0),[feat+'_0len_save']]=varia_list['d15'+str(12)].loc[(varia_list['d15'+str(12)][feat]==0),][feat+'_0len'].apply(lambda x:1 if pd.isnull(x) else int(x)+1)\n",
    "            varia_list['d15'+str(12)].loc[(varia_list['d15'+str(12)][feat]==1),[feat+'_0len_save']]=0\n",
    "        else:\n",
    "            varia_list['d15'+str(12)].loc[(varia_list['d15'+str(12)][feat]==0),[feat+'_0len_save']]=1\n",
    "        temp=varia_list['d15'+str(12)].loc[:,['ncodpers',feat+'_0len_save']].rename(columns={feat+'_0len_save':feat+'_0len'}) \n",
    "        varia_list['d16'+str(1)] =  varia_list['d16'+str(1)].merge(temp, on='ncodpers', how='left')  \n",
    "#2016年\n",
    "        for i in range(1,6): \n",
    "            varia_list['d16'+str(i)][feat+'_0len_save']=np.zeros((varia_list['d16'+str(i)].shape[0],))\n",
    "            if feat+'_0len' in  varia_list['d16'+str(i)].columns:\n",
    "               varia_list['d16'+str(i)].loc[(varia_list['d16'+str(i)][feat]==0),[feat+'_0len_save']]=varia_list['d16'+str(i)].loc[(varia_list['d16'+str(i)][feat]==0),][feat+'_0len'].apply(lambda x:1 if pd.isnull(x) else int(x)+1)\n",
    "               varia_list['d16'+str(i)].loc[(varia_list['d16'+str(i)][feat]==1),[feat+'_0len_save']]=0\n",
    "            else:\n",
    "               varia_list['d16'+str(i)].loc[(varia_list['d16'+str(i)][feat]==0),[feat+'_0len_save']]=1\n",
    "            temp=varia_list['d16'+str(i)].loc[:,['ncodpers',feat+'_0len_save']].rename(columns={feat+'_0len_save':feat+'_0len'}) \n",
    "            varia_list['d16'+str(i+1)] =  varia_list['d16'+str(i+1)].merge(temp, on='ncodpers', how='left')    \n",
    "#drop掉那些只用来存储中间值的特征\n",
    "        for i in range(1,13):\n",
    "            varia_list['d15'+str(i)].drop([feat+'_0len_save'],axis=1, inplace=True)\n",
    "        for i in range(1,6):\n",
    "            varia_list['d16'+str(i)].drop([feat+'_0len_save'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#这个月是否有买了相应产品，将其作为一列，1为买了，0为没买,届时是作为训练用的标签，标签名为feat+'_new_purchase'\n",
    "#df是以月份切割出的数据集\n",
    "def pruchase_or_not(df,features=[]):\n",
    "  for feat in features:  \n",
    "   \n",
    "       df[feat+'_new_purchase']=np.zeros((df.shape[0],))\n",
    "       df.loc[(df[feat+'_last_month']==0) & (df[feat]==1),[feat+'_new_purchase']]=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target需要是字符串型,代表用哪个target来做mean value of the target variable\n",
    "#df1是个用月份切割出来的数据集，用该数据集的mean value of the target variable作为\n",
    "#df2数据集对应concaten_product特征的替代\n",
    "def concaten_product_last_month(target,df1,df2):\n",
    "    if  target+'_new_purchase' not in df1.columns:   \n",
    "        pruchase_or_not(df1,features=[target]) \n",
    "        \n",
    "    products_last_month=[ \n",
    "           'ind_cco_fin_ult1_last_month', 'ind_cder_fin_ult1_last_month',\n",
    "           'ind_cno_fin_ult1_last_month', 'ind_ctju_fin_ult1_last_month',\n",
    "           'ind_ctma_fin_ult1_last_month', 'ind_ctop_fin_ult1_last_month',\n",
    "           'ind_ctpp_fin_ult1_last_month', 'ind_dela_fin_ult1_last_month',\n",
    "           'ind_ecue_fin_ult1_last_month', 'ind_fond_fin_ult1_last_month',\n",
    "           'ind_hip_fin_ult1_last_month', 'ind_plan_fin_ult1_last_month',\n",
    "           'ind_pres_fin_ult1_last_month', 'ind_reca_fin_ult1_last_month',\n",
    "           'ind_tjcr_fin_ult1_last_month', 'ind_valo_fin_ult1_last_month',\n",
    "           'ind_viv_fin_ult1_last_month', 'ind_nomina_ult1_last_month',\n",
    "           'ind_nom_pens_ult1_last_month', 'ind_recibo_ult1_last_month']\n",
    "    \n",
    "\n",
    "    temp=df1.groupby(products_last_month)[target+'_new_purchase'].value_counts().unstack().reset_index().rename(columns={0:'no', 1:'yes'})\n",
    "    temp['yes']=temp['yes'].apply(lambda x:0 if pd.isnull(x) else int(x))\n",
    "    temp['no']=temp['no'].apply(lambda x:0 if pd.isnull(x) else int(x))\n",
    "    temp['concaten_product_target_mean']=temp['yes']/(temp['yes']+temp['no'])\n",
    "    temp.drop(['yes','no'],axis=1, inplace=True)\n",
    "   \n",
    " \n",
    "    df1['concaten_product_target_mean']= df1.merge(temp, on=products_last_month, how='left')['concaten_product_target_mean']\n",
    "    df2['concaten_product_target_mean']= df2.merge(temp, on=products_last_month, how='left')['concaten_product_target_mean']\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将这个月与上个月对应特征的特征值concaten后用相应的mean value of the target variable代替\n",
    "#这里传入的feats按作者的想法是只有'indactividadcliente'和'tiprel_1mes'两种\n",
    "#df1是个用月份切割出来的数据集，用该数据集的mean value of the target variable作为\n",
    "#df2数据集concaten_feat特征的替代\n",
    "def concaten_now_last_month(target,df1,df2,feats=[]):\n",
    "  df1,df2\n",
    "  if  target+'_new_purchase' not in df1.columns:   \n",
    "     pruchase_or_not(df1,features=[target]) \n",
    "    \n",
    "  for feat in feats:\n",
    "     temp=df1.groupby([feat,feat+'_last_month'])[target+'_new_purchase'].value_counts().unstack().reset_index().rename(columns={0:'no', 1:'yes'})\n",
    "     temp['yes']=temp['yes'].apply(lambda x:0 if pd.isnull(x) else int(x))\n",
    "     temp['no']=temp['no'].apply(lambda x:0 if pd.isnull(x) else int(x))\n",
    "     temp['concaten_'+feat+'_target_mean']=temp['yes']/(temp['yes']+temp['no'])\n",
    "     temp.drop(['yes','no'],axis=1, inplace=True)\n",
    "\n",
    "     df1['concaten_'+feat+'_target_mean']=df1.merge(temp, on=[feat,feat+'_last_month'], how='left')['concaten_'+feat+'_target_mean']\n",
    "     df2['concaten_'+feat+'_target_mean']=df2.merge(temp, on=[feat,feat+'_last_month'], how='left')['concaten_'+feat+'_target_mean']              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "products=[ 'ind_cco_fin_ult1',  'ind_cder_fin_ult1', 'ind_cno_fin_ult1', 'ind_ctju_fin_ult1',\n",
    "       'ind_ctma_fin_ult1', 'ind_ctop_fin_ult1', 'ind_ctpp_fin_ult1',\n",
    "       'ind_dela_fin_ult1', 'ind_ecue_fin_ult1', 'ind_fond_fin_ult1', 'ind_hip_fin_ult1',\n",
    "       'ind_plan_fin_ult1', 'ind_pres_fin_ult1', 'ind_reca_fin_ult1',\n",
    "       'ind_tjcr_fin_ult1', 'ind_valo_fin_ult1', 'ind_viv_fin_ult1',\n",
    "       'ind_nomina_ult1', 'ind_nom_pens_ult1', 'ind_recibo_ult1']\n",
    "features=products+['ind_actividad_cliente','tiprel_1mes']\n",
    "#构建数据集，\n",
    "def build_dataset_for_all():\n",
    "    get_last_month_feat(features)\n",
    "    count_index_change_pattern(products)\n",
    "    get_n_products_last()\n",
    "    get_length_conti0(products)\n",
    "    \n",
    "#以上是对所有数据集统一处理的部分,可以先写到csv中\n",
    "#可以拆开一条一条运行做测试    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    " #这里仅用做测试\n",
    "    get_last_month_feat(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1作为训练集，df2作为验证集or测试集，target是选择哪个product作为标签，作者的想法\n",
    "#是训练一堆二分类器，最后把结果融合起来\n",
    "#比如build_dataset_for_each('ind_valo_fin_ult1',d165,d166),即是以16年5月28日作为训练集，\n",
    "#16年5月28日作为测试集构建数据集，'ind_valo_fin_ult1_new_purchase'作为标签，1代表买了，0代表没买\n",
    "\n",
    "def build_dataset_for_each(target,df1,df2,):\n",
    "   concaten_product_last_month(target,df1,df2,)\n",
    "#feats按作者的想法是只有'ind_actividad_cliente'和'tiprel_1mes'两种\n",
    "   concaten_now_last_month(target,df1,df2,feats=['ind_actividad_cliente','tiprel_1mes'])\n",
    "#concaten完'ind_actividad_cliente_last_month','tiprel_1mes_last_month'就不需要了\n",
    "   df1.drop(['ind_actividad_cliente_last_month','tiprel_1mes_last_month'],axis=1, inplace=True)\n",
    "   df2.drop(['ind_actividad_cliente_last_month','tiprel_1mes_last_month'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#以下是用2015-12-28作为训练集，2016-06-28作为测试集,预测'ind_cco_fin_ult1'被购买的概率，但这只是生成数据集，后面还要结合lightgbm等进行训练\n",
    "#build_dataset_for_all()\n",
    "#以下用于测试\n",
    "build_dataset_for_each('ind_cco_fin_ult1',d1512,d166)\n",
    "\n",
    "\n",
    "#再剔除掉新用户(上个月没有记录)以及买过相应产品的用户（上个月已经买了这个产品）\n",
    "d1512=d1512[(d1512['ind_cco_fin_ult1'+'_last_month']==0)]\n",
    "d166=d166[(d166['ind_cco_fin_ult1'+'_last_month']==0)]\n",
    "#这里还没封装好，仅先做测试\n",
    "\n",
    "#用于Xgboost等工具直接训练的数据集还须再稍微处理下，还须特征的归特征，标签的归标签！！！\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fecha_dato', 'ncodpers', 'ind_empleado', 'pais_residencia', 'sexo',\n",
       "       'age', 'ind_nuevo', 'antiguedad', 'indrel', 'indrel_1mes',\n",
       "       'tiprel_1mes', 'indresi', 'indext', 'conyuemp', 'canal_entrada',\n",
       "       'indfall', 'nomprov', 'ind_actividad_cliente', 'renta', 'segmento',\n",
       "       'ind_ahor_fin_ult1', 'ind_aval_fin_ult1', 'ind_cco_fin_ult1',\n",
       "       'ind_cder_fin_ult1', 'ind_cno_fin_ult1', 'ind_ctju_fin_ult1',\n",
       "       'ind_ctma_fin_ult1', 'ind_ctop_fin_ult1', 'ind_ctpp_fin_ult1',\n",
       "       'ind_deco_fin_ult1', 'ind_deme_fin_ult1', 'ind_dela_fin_ult1',\n",
       "       'ind_ecue_fin_ult1', 'ind_fond_fin_ult1', 'ind_hip_fin_ult1',\n",
       "       'ind_plan_fin_ult1', 'ind_pres_fin_ult1', 'ind_reca_fin_ult1',\n",
       "       'ind_tjcr_fin_ult1', 'ind_valo_fin_ult1', 'ind_viv_fin_ult1',\n",
       "       'ind_nomina_ult1', 'ind_nom_pens_ult1', 'ind_recibo_ult1',\n",
       "       'ind_cco_fin_ult1_last_month', 'ind_cder_fin_ult1_last_month',\n",
       "       'ind_cno_fin_ult1_last_month', 'ind_ctju_fin_ult1_last_month',\n",
       "       'ind_ctma_fin_ult1_last_month', 'ind_ctop_fin_ult1_last_month',\n",
       "       'ind_ctpp_fin_ult1_last_month', 'ind_dela_fin_ult1_last_month',\n",
       "       'ind_ecue_fin_ult1_last_month', 'ind_fond_fin_ult1_last_month',\n",
       "       'ind_hip_fin_ult1_last_month', 'ind_plan_fin_ult1_last_month',\n",
       "       'ind_pres_fin_ult1_last_month', 'ind_reca_fin_ult1_last_month',\n",
       "       'ind_tjcr_fin_ult1_last_month', 'ind_valo_fin_ult1_last_month',\n",
       "       'ind_viv_fin_ult1_last_month', 'ind_nomina_ult1_last_month',\n",
       "       'ind_nom_pens_ult1_last_month', 'ind_recibo_ult1_last_month',\n",
       "       'ind_cco_fin_ult1_new_purchase', 'concaten_product_target_mean',\n",
       "       'concaten_ind_actividad_cliente_target_mean',\n",
       "       'concaten_tiprel_1mes_target_mean'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1512.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fecha_dato', 'ncodpers', 'ind_empleado', 'pais_residencia', 'sexo',\n",
       "       'age', 'ind_nuevo', 'antiguedad', 'indrel', 'indrel_1mes',\n",
       "       'tiprel_1mes', 'indresi', 'indext', 'conyuemp', 'canal_entrada',\n",
       "       'indfall', 'nomprov', 'ind_actividad_cliente', 'renta', 'segmento',\n",
       "       'ind_ahor_fin_ult1', 'ind_aval_fin_ult1', 'ind_cco_fin_ult1',\n",
       "       'ind_cder_fin_ult1', 'ind_cno_fin_ult1', 'ind_ctju_fin_ult1',\n",
       "       'ind_ctma_fin_ult1', 'ind_ctop_fin_ult1', 'ind_ctpp_fin_ult1',\n",
       "       'ind_deco_fin_ult1', 'ind_deme_fin_ult1', 'ind_dela_fin_ult1',\n",
       "       'ind_ecue_fin_ult1', 'ind_fond_fin_ult1', 'ind_hip_fin_ult1',\n",
       "       'ind_plan_fin_ult1', 'ind_pres_fin_ult1', 'ind_reca_fin_ult1',\n",
       "       'ind_tjcr_fin_ult1', 'ind_valo_fin_ult1', 'ind_viv_fin_ult1',\n",
       "       'ind_nomina_ult1', 'ind_nom_pens_ult1', 'ind_recibo_ult1',\n",
       "       'ind_cco_fin_ult1_last_month', 'ind_cder_fin_ult1_last_month',\n",
       "       'ind_cno_fin_ult1_last_month', 'ind_ctju_fin_ult1_last_month',\n",
       "       'ind_ctma_fin_ult1_last_month', 'ind_ctop_fin_ult1_last_month',\n",
       "       'ind_ctpp_fin_ult1_last_month', 'ind_dela_fin_ult1_last_month',\n",
       "       'ind_ecue_fin_ult1_last_month', 'ind_fond_fin_ult1_last_month',\n",
       "       'ind_hip_fin_ult1_last_month', 'ind_plan_fin_ult1_last_month',\n",
       "       'ind_pres_fin_ult1_last_month', 'ind_reca_fin_ult1_last_month',\n",
       "       'ind_tjcr_fin_ult1_last_month', 'ind_valo_fin_ult1_last_month',\n",
       "       'ind_viv_fin_ult1_last_month', 'ind_nomina_ult1_last_month',\n",
       "       'ind_nom_pens_ult1_last_month', 'ind_recibo_ult1_last_month',\n",
       "       'concaten_product_target_mean',\n",
       "       'concaten_ind_actividad_cliente_target_mean',\n",
       "       'concaten_tiprel_1mes_target_mean'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d166.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
